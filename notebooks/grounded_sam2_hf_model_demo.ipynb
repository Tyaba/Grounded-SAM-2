{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/appuser/Grounded-SAM-2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import supervision as sv\n",
    "import torch\n",
    "from PIL import Image\n",
    "from supervision.draw.color import ColorPalette\n",
    "from transformers import AutoModelForZeroShotObjectDetection, AutoProcessor\n",
    "\n",
    "from sam2.build_sam import build_sam2\n",
    "from sam2.sam2_image_predictor import SAM2ImagePredictor\n",
    "from utils.supervision_utils import CUSTOM_COLOR_MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# environment settings\n",
    "# use bfloat16\n",
    "torch.autocast(device_type=\"cuda\", dtype=torch.bfloat16).__enter__()\n",
    "\n",
    "if torch.cuda.get_device_properties(0).major >= 8:\n",
    "    # turn on tfloat32 for Ampere GPUs (https://pytorch.org/docs/stable/notes/cuda.html#tensorfloat-32-tf32-on-ampere-devices)\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    torch.backends.cudnn.allow_tf32 = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build SAM2 image predictor\n",
    "sam2_checkpoint = \"./checkpoints/sam2_hiera_large.pt\"\n",
    "model_cfg = \"sam2_hiera_l.yaml\"\n",
    "sam2_model = build_sam2(model_cfg, sam2_checkpoint, device=\"cuda\")\n",
    "sam2_predictor = SAM2ImagePredictor(sam2_model)\n",
    "\n",
    "# build grounding dino from huggingface\n",
    "model_id = \"IDEA-Research/grounding-dino-tiny\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "grounding_model = AutoModelForZeroShotObjectDetection.from_pretrained(model_id).to(\n",
    "    device\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the input image and text prompt for SAM 2 and Grounding DINO\n",
    "# VERY important: text queries need to be lowercased + end with a dot\n",
    "text = \"car. tire.\"\n",
    "img_path = \"notebooks/images/truck.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open(img_path)\n",
    "\n",
    "sam2_predictor.set_image(np.array(image.convert(\"RGB\")))\n",
    "\n",
    "inputs = processor(images=image, text=text, return_tensors=\"pt\").to(device)\n",
    "with torch.no_grad():\n",
    "    outputs = grounding_model(**inputs)\n",
    "\n",
    "# results of Grounding DINO\n",
    "results = processor.post_process_grounded_object_detection(\n",
    "    outputs,\n",
    "    inputs.input_ids,\n",
    "    box_threshold=0.4,\n",
    "    text_threshold=0.3,\n",
    "    target_sizes=[image.size[::-1]],\n",
    ")\n",
    "\n",
    "# get the box prompt for SAM 2\n",
    "input_boxes = results[0][\"boxes\"].cpu().numpy()\n",
    "\n",
    "# results of SAM 2\n",
    "masks, scores, logits = sam2_predictor.predict(\n",
    "    point_coords=None,\n",
    "    point_labels=None,\n",
    "    box=input_boxes,\n",
    "    multimask_output=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the shape to (n, H, W)\n",
    "if masks.ndim == 4:\n",
    "    masks = masks.squeeze(1)\n",
    "\n",
    "\n",
    "confidences = results[0][\"scores\"].cpu().numpy().tolist()\n",
    "class_names = results[0][\"labels\"]\n",
    "class_ids = np.array(list(range(len(class_names))))\n",
    "\n",
    "labels = [\n",
    "    f\"{class_name} {confidence:.2f}\"\n",
    "    for class_name, confidence in zip(class_names, confidences)\n",
    "]\n",
    "\n",
    "\"\"\"\n",
    "Visualize image with supervision useful API\n",
    "\"\"\"\n",
    "img = cv2.imread(img_path)\n",
    "detections = sv.Detections(\n",
    "    xyxy=input_boxes,  # (n, 4)\n",
    "    mask=masks.astype(bool),  # (n, h, w)\n",
    "    class_id=class_ids,\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "Note that if you want to use default color map,\n",
    "you can set color=ColorPalette.DEFAULT\n",
    "\"\"\"\n",
    "box_annotator = sv.BoxAnnotator(color=ColorPalette.from_hex(CUSTOM_COLOR_MAP))\n",
    "annotated_frame = box_annotator.annotate(scene=img.copy(), detections=detections)\n",
    "\n",
    "label_annotator = sv.LabelAnnotator(color=ColorPalette.from_hex(CUSTOM_COLOR_MAP))\n",
    "annotated_frame = label_annotator.annotate(\n",
    "    scene=annotated_frame, detections=detections, labels=labels\n",
    ")\n",
    "cv2.imwrite(\"groundingdino_annotated_image.jpg\", annotated_frame)\n",
    "\n",
    "mask_annotator = sv.MaskAnnotator(color=ColorPalette.from_hex(CUSTOM_COLOR_MAP))\n",
    "annotated_frame = mask_annotator.annotate(scene=annotated_frame, detections=detections)\n",
    "cv2.imwrite(\"grounded_sam2_annotated_image_with_mask.jpg\", annotated_frame)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
